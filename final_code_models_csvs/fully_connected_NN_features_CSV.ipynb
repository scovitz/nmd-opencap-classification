{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf \n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input data and labels\n",
    "features_df = pd.read_csv('/Users/scovitz/datadir/video_features.csv')\n",
    "labels_csv = '/Users/scovitz/datadir/class_info.csv'\n",
    "class_df = pd.read_csv(labels_csv)\n",
    "\n",
    "# convert to numpy\n",
    "X = features_df.iloc[:, 2:].to_numpy()  # All columns except the first two (features)\n",
    "y = class_df.iloc[:, -1].to_numpy()   # The last column (labels)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)  # If validation set exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1694ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried focal loss, did not work \n",
    "\n",
    "# def focal_loss(gamma=2., alpha=0.25):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         return -alpha * tf.pow(1. - pt_1, gamma) * tf.math.log(pt_1) - \\\n",
    "#                (1 - alpha) * tf.pow(pt_0, gamma) * tf.math.log(1. - pt_0)\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0419443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, use L2 regularization\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # Input Layer, First Hidden Layer\n",
    "    model.add(Dense(64, input_shape=input_shape, activation='relu', kernel_regularizer=l2(0.01)))  # Add L2 regularization\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))  # Dropout to reduce overfitting\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))  # Add L2 regularization\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Third Hidden Layer\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))  # Add L2 regularization\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary output --> sigmoid for output layer \n",
    "    \n",
    "    # Compile the model using focal loss \n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "#               loss=focal_loss(gamma=2., alpha=0.25), \n",
    "#               metrics=['accuracy'])\n",
    "    \n",
    "    # Compile the model, use Adam and BCE Loss\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train.shape[1],)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Compute class weights to balance the dataset\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class Weights: {class_weight_dict}\")\n",
    "\n",
    "# Train the model with class weights dict\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=70,\n",
    "    batch_size=16,\n",
    "    verbose=1,\n",
    "    class_weight=class_weight_dict  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece87b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# evaluation\n",
    "# Print final training and validation accuracy\n",
    "final_train_accuracy = history.history['accuracy'][-1]\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy}\")\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Compute the weighted F1 score\n",
    "test_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print('Weighted F1 Score: ', test_f1)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss - Features CSV')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0368e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class\n",
    "y_pred_prob = model.predict(X_test).ravel()  # `.ravel()` ensures 1D array\n",
    "\n",
    "# Compute ROC Curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute Precision-Recall Curve and AUPRC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "average_precision = average_precision_score(y_test, y_pred_prob)\n",
    "weighted_recall = classification_report(y_test, (y_pred_prob > 0.5).astype(int), output_dict=True)['weighted avg']['recall']\n",
    "weighted_precision = classification_report(y_test, (y_pred_prob > 0.5).astype(int), output_dict=True)['weighted avg']['precision']\n",
    "\n",
    "print('weighted average precision: ', weighted_precision)\n",
    "print(\"average recall: \", weighted_recall)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f'PR curve (AUPRC = {average_precision:.2f})', color='green')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (PR) Curve')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
